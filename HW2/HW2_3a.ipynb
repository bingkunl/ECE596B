{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit\n",
    "from sklearn.utils import shuffle\n",
    "from load_cifar import *\n",
    "import time\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extract MNIST data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# get mnist data, with one_hot encoding, reshape = False (that means images are not flatten)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",reshape=False,one_hot=True)\n",
    "# suppress warnings\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prepare training, validation and testing data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = mnist.train.images, mnist.train.labels\n",
    "x_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "# pad images with 0s (28x28 to 32x32)\n",
    "x_train_pad = np.pad(x_train, ((0,0), (2,2), (2,2), (0,0)), mode='constant', constant_values=0)\n",
    "x_validation_pad = np.pad(x_validation, ((0,0), (2,2), (2,2), (0,0)), mode='constant', constant_values=0)\n",
    "x_test_pad = np.pad(x_test, ((0,0), (2,2), (2,2), (0,0)), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0007\n",
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,32,32,1],name='X')\n",
    "Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')\n",
    "Training = tf.placeholder(tf.bool, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:1: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:3: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:5: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:11: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:19: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:19: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c41e8db3ddcd>:27: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\envname\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "C1 = tf.layers.conv2d(X, filters=6, kernel_size=5, activation=tf.nn.relu)\n",
    "\n",
    "S2 = tf.layers.max_pooling2d(C1, pool_size=2, strides=2)\n",
    "\n",
    "S2_bn = tf.layers.batch_normalization(S2)\n",
    "\n",
    "# S2_bn = tf.nn.relu(S2_bn)\n",
    "\n",
    "C3 = tf.layers.conv2d(S2_bn, filters=16, kernel_size=5, activation=tf.nn.relu)\n",
    "\n",
    "S4 = tf.layers.average_pooling2d(C3, pool_size=2, strides=2)\n",
    "\n",
    "S4_bn = tf.layers.batch_normalization(S4)\n",
    "\n",
    "# S4_bn = tf.nn.relu(S4_bn)\n",
    "\n",
    "# F5 = tf.layers.flatten(tf.layers.conv2d(S4, filters=120, kernel_size=5, activation=tf.nn.relu))\n",
    "\n",
    "F5 = tf.layers.dense(tf.layers.flatten(S4_bn), units=120, activation=tf.nn.relu)\n",
    "\n",
    "# F5 = tf.layers.dropout(F5, rate=0.6, training=Training)\n",
    "\n",
    "F5_bn = tf.layers.batch_normalization(F5)\n",
    "\n",
    "F6 = tf.layers.dense(F5_bn, units=84, activation=tf.nn.relu)\n",
    "\n",
    "F6 = tf.layers.dropout(F6, rate=0.6, training=Training)\n",
    "\n",
    "F6_bn = tf.layers.batch_normalization(F6)\n",
    "\n",
    "logits = tf.layers.dense(F6_bn, units=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y),name='loss')\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# compare the predicted labels with true labels\n",
    "correct_pred = tf.equal(tf.argmax(tf.nn.softmax(logits),1),tf.argmax(Y,1))\n",
    "\n",
    "# compute the accuracy by taking average\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validating, testing</h1>\n",
    "<h2>1. Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2. Print out training time on each epoch</h2>\n",
    "<h2>3. Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0   Time:3.324   Current validation accuracy: 0.9572\n",
      "Epoch:1   Time:1.682   Current validation accuracy: 0.9732\n",
      "Epoch:2   Time:1.669   Current validation accuracy: 0.9794\n",
      "Epoch:3   Time:1.677   Current validation accuracy: 0.9812\n",
      "Epoch:4   Time:1.659   Current validation accuracy: 0.985\n",
      "Epoch:5   Time:1.680   Current validation accuracy: 0.9868\n",
      "Epoch:6   Time:1.656   Current validation accuracy: 0.9862\n",
      "Epoch:7   Time:1.651   Current validation accuracy: 0.9872\n",
      "Epoch:8   Time:1.649   Current validation accuracy: 0.9886\n",
      "Epoch:9   Time:1.652   Current validation accuracy: 0.9888\n",
      "Epoch:10   Time:1.651   Current validation accuracy: 0.9898\n",
      "Epoch:11   Time:1.649   Current validation accuracy: 0.9898\n",
      "Epoch:12   Time:1.650   Current validation accuracy: 0.9904\n",
      "Epoch:13   Time:1.652   Current validation accuracy: 0.99\n",
      "Epoch:14   Time:1.646   Current validation accuracy: 0.99\n",
      "Epoch:15   Time:1.662   Current validation accuracy: 0.9908\n",
      "Epoch:16   Time:1.655   Current validation accuracy: 0.9904\n",
      "Epoch:17   Time:1.650   Current validation accuracy: 0.99\n",
      "Epoch:18   Time:1.691   Current validation accuracy: 0.9912\n",
      "Epoch:19   Time:1.699   Current validation accuracy: 0.992\n",
      "Test accuracy: \n",
      "0.9907\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_epochs):\n",
    "        s = time.time()\n",
    "        data_batch = mini_batch(x_train_pad, y_train, batch_size)\n",
    "        for x, y in data_batch:\n",
    "            sess.run(train_op, feed_dict = {X: x, Y: y, Training: True})\n",
    "        validation_acc = sess.run(accuracy, feed_dict = {X:x_validation_pad, Y:y_validation, Training: False})\n",
    "        f = time.time()\n",
    "        print('Epoch:' + str(i) + '   Time:{:.3f}'.format(f - s) + '   Current validation accuracy: ' + str(validation_acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict = {X:x_test_pad, Y:y_test, Training: False})\n",
    "    print('Test accuracy: ')\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
